#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Dec 16 15:42:19 2022

@author: cringwal
"""
import requests
from ratelimit import limits, RateLimitException, sleep_and_retry

keyword="'extraction AND relation AND survey'"
year=2017
openalex_url = "https://api.openalex.org/works?search="+keyword+"&filter=publication-year:"+str(year)+"&per-page=200&page={}"
cursor = '*'
# ALSO POSSIBLE TO FILTER MORE PRECISELY DEPENDING ON ASTRACT, TITLE ...
# loop through pages

ONE_SEC = 1
MAX_CALLS_PER_SECOND = 10

@sleep_and_retry
@limits(calls=MAX_CALLS_PER_SECOND, period=ONE_SEC)
def access_rate_limited_api(url):
    resp = requests.get(url)
    return resp


page = 1
has_more_pages = True
fewer_than_10k_results = True

# loop through pages
while has_more_pages and fewer_than_10k_results:
    
    # set page value and request page from OpenAlex
    url = openalex_url.format(page)
    print('\n' + url)
    
    response=access_rate_limited_api(url)
    page_with_results =response.json()
    
    # loop through partial list of results
    results = page_with_results['results']
    for i,work in enumerate(results):
        openalex_id = work['id'].replace("https://openalex.org/", "")
        print(openalex_id, end='\t' if (i+1)%5!=0 else '\n')

    # next page
    page += 1
    
    # end loop when either there are no more results on the requested page 
    # or the next request would exceed 10,000 results
    per_page = page_with_results['meta']['per_page']
    total=int(page_with_results['meta']['count'])
    has_more_pages = len(results) == per_page
    
    print(">>>>>",page,"/",total)
    #fewer_than_10k_results = per_page * page <= 10000
    fewer_than_10k_results = total <= 10000
    if(fewer_than_10k_results == False):
        print("QUERY TOO LARGE MUST BE REVIEWED")
